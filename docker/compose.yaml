# Default compose file - uses Zookeeper mode (stable, well-tested)
# For KRaft mode, use: docker compose -f compose-kraft.yaml up -d
#
# Configuration:
#   Copy ../.env.example to ../.env and customize values
#   Or set environment variables directly before running docker compose

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2182:2181"
    networks:
      - crypto-network

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    networks:
      - crypto-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.10.2
    container_name: mlflow-server
    ports:
      - "5001:5000"
    volumes:
      # Mount local directory for MLflow data and artifacts
      - ./mlflow_data:/mlflow
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow/mlflow.db
      --artifacts-destination /mlflow/artifacts
      --default-artifact-root http://localhost:5001/api/2.0/mlflow-artifacts/artifacts/experiments
      --host 0.0.0.0
      --port 5000
      --serve-artifacts
    networks:
      - crypto-network
    # Healthcheck removed - MLflow doesn't need curl/wget for healthcheck
    # The service will start and be available, healthcheck is optional

  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.api
    container_name: volatility-api
    ports:
      - "8000:8000"
    environment:
      # Model variant toggle: "ml" for trained model, "baseline" for z-score fallback
      # Change to "baseline" for rollback: MODEL_VARIANT=baseline
      - MODEL_VARIANT=${MODEL_VARIANT:-ml}
      - MODEL_VERSION=${MODEL_VERSION:-random_forest}
      - MODEL_PATH=/app/models/artifacts/${MODEL_VERSION:-random_forest}/model.pkl
      - BASELINE_MODEL_PATH=/app/models/artifacts/baseline/model.pkl
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092
      - GIT_SHA=${GIT_SHA:-dev}
    volumes:
      - ../models:/app/models:ro
      - ../data:/app/data:ro
    depends_on:
      kafka:
        condition: service_healthy
      mlflow:
        condition: service_started  # Changed from service_healthy - MLflow healthcheck is optional
    networks:
      - crypto-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/alerts.yml:/etc/prometheus/alerts.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.enable-lifecycle'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - crypto-network
    depends_on:
      - api
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
      # Enable anonymous access so users can view dashboards without login
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
      - GF_AUTH_ANONYMOUS_ORG_NAME=Main Org.
      # Allow Grafana to start even if datasource provisioning fails initially
      - GF_DATABASE_MAX_IDLE_CONN=2
      - GF_DATABASE_MAX_OPEN_CONN=0
      - GF_DATABASE_CONN_MAX_LIFETIME=14400
      # Disable strict provisioning validation (allows Grafana to start even if datasource fails)
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro
    networks:
      - crypto-network
    depends_on:
      prometheus:
        condition: service_healthy
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/api/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  crypto-network:
    driver: bridge

volumes:
  kafka-data:
  prometheus-data:
  grafana-data:

# Note: Kafka is now running in KRaft mode (no Zookeeper needed)
# MLflow data is stored in ./mlflow_data (bind mount)
# API service loads models from ../models (read-only mount)
